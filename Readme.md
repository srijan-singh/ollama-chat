# Ollama Chat - VS Code Extension

![Ollama Chat](https://img.shields.io/badge/VS%20Code-Extension-blue.svg)

Ollama Chat is a Visual Studio Code extension that allows seamless interaction with a locally running Ollama model. It enhances the coding experience by providing AI-assisted suggestions and responses directly within the editor.

## Features

- **Local AI Integration**: Connects with an Ollama model running on your machine.
- **Interactive Chat**: Engage in AI-powered discussions without leaving VS Code.
- **Code Assistance**: Get contextual suggestions and explanations for your code.
- **Customizable Settings**: Configure model parameters as per your needs.

## Installation

1. Clone this repository:
   ```sh
   git clone https://github.com/srijan-singh/ollama-chat.git
   cd ollama-chat
   ```
2. Install dependencies:
   ```sh
   npm install
   ```

## Usage

1. Open VS Code.
2. Press `Cmd + Shift + P` (Mac) or `Ctrl + Shift + P` (Windows/Linux).
3. Search for "Ollama Chat: Start Session" and select it.
4. Interact with the Ollama model in the chat panel.

## Contributing

Contributions are welcome! Feel free to submit issues or pull requests.

## License

This project is licensed under the [MIT License](LICENSE).

